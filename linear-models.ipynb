{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS\n",
    "\n",
    "* coefficients w = (w1,...wn) to minimize residual sum of squares\n",
    "* relies on model terms being independent.\n",
    "* complexity = O(n*p^2) for matrix of size (n,p)\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) |\n",
    "[example](plot_ols.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit ([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE\n",
    "\n",
    "* Uses alpha param to control shrinkage.\n",
    "* As alpha grows, shinkage grows == coefficients are more tolerant of collinearity.\n",
    "* Same complexity as OLS.\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) |\n",
    "[ridge path vs alpha](plot_ridge_path.ipynb) | \n",
    "[OLS ridge variance](plot_ols_ridge_variance.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.34545455,  0.34545455]), 0.13636363636363641)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge (alpha = .5)\n",
    "reg.fit ([[0, 0], [0, 0], [1, 1]], [0, .1, 1]) \n",
    "\n",
    "reg.coef_, reg.intercept_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE WITH CV\n",
    "\n",
    "* Uses generalized cross-validation (GCV) = leave-one-out CV.\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV) |\n",
    "[multi-out face completion](plot_multioutput_face_completion.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10000000000000001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1])       \n",
    "\n",
    "reg.alpha_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO\n",
    "\n",
    "* Linear model, estimates sparse coefficients.\n",
    "* Useful in compressed sensing, also can be used for feature selection.\n",
    "* Uses coordinate descent as the fitting algorithm.\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) |\n",
    "[sparse signals: lasso v elasticnet](plot_lasso_and_elasticnet.ipynb) | [lasso compression sensing](plot_tomography_l1_reconstruction.ipynb) | [lasso model selection](plot_lasso_model_selection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Lasso(alpha = 0.1)\n",
    "reg.fit([[0, 0], [1, 1]], [0, 1])\n",
    "\n",
    "reg.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO (MULTITASK)\n",
    "\n",
    "* sparse coefficients, multi regressions\n",
    "* y = 2D (#samples, #tasks); #tasks = same for all samples\n",
    "* Trained with mixed l1,l2 prior as regularizer.\n",
    "* Uses [Frobenius norm](https://en.wikipedia.org/wiki/Matrix_norm) in objective function.\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskLasso.html#sklearn.linear_model.MultiTaskLasso) |\n",
    "[joint feature selection](plot_multi_task_lasso_support.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ELASTICNET\n",
    "\n",
    "* Trained with l1,l2 prior as regularizer.\n",
    "* Replicates regularization properties of [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge).\n",
    "* `l1_ratio` = l1,l2 convex combo\n",
    "* Use case: linear regression, #multiple correlated features.\n",
    "* alpha, l1_ratio can be set by [cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV): \n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet) | [sparse signals: elasticnet v lasso](plot_lasso_and_elasticnet.ipynb) | [coordinate descent path - lasso](plot_lasso_coordinate_descent_path.ipynb) | [multi-task lasso (API)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELASTICNET (MULTITASK)\n",
    "\n",
    "* sparse coefficients, multi regressions\n",
    "* y= 2D (#samples, #tasks); #tasks = same for all samples\n",
    "* Uses coordinate descent for fitting\n",
    "* alpha, l1_ratio ca be set by [cross_validation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNetCV.html#sklearn.linear_model.MultiTaskElasticNetCV).\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.MultiTaskElasticNet.html#sklearn.linear_model.MultiTaskElasticNet) |\n",
    "[demo](plot_multi_task_lasso_support.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEAST ANGLE REGRESSION (LARS)\n",
    "\n",
    "* For high-D datasets (p>>n)\n",
    "* Same complexity as OLS\n",
    "* Full piecewise linear solution path (good for CVs)\n",
    "* Noise sensitivity?\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html#sklearn.linear_model.Lars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     -1.1111]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lars(n_nonzero_coefs=1)\n",
    "clf.fit([\n",
    "        [-1, 1], [0, 0], [1, 1]], \n",
    "        [-1.1111, 0, -1.1111])\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LARS LASSO\n",
    "\n",
    "* Lasso model / LARS algo\n",
    "* returns solution curve for each l1 norm value\n",
    "* stored in coef_path_ (#features, max_features+1). 1st col always zero.\n",
    "\n",
    "[api](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLars.html#sklearn.linear_model.LassoLars) | [find lasso path on lars algo, diabetes dataset](plot_lasso_lars.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71715729,  0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LassoLars(alpha=.1)\n",
    "reg.fit([[0, 0], [1, 1]], [0, 1])  \n",
    "reg.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OMP\n",
    "\n",
    "* uses l0 pseudonorm\n",
    "* finds \"atom most correlated with current residual\"\n",
    "* \"residual is recomputed using orthogonal projection...\n",
    "* \"...on space of prev chosen dict elements\"\n",
    "\n",
    "[OMP](https://en.wikipedia.org/wiki/Matching_pursuit) |\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.OrthogonalMatchingPursuit.html#sklearn.linear_model.OrthogonalMatchingPursuit) |\n",
    "[example](plot_omp.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAYES REGRESSION, BAYES RIDGE REGRESSION\n",
    "\n",
    "* introduces [uninformative priors](https://en.wikipedia.org/wiki/Non-informative_prior#Uninformative_priors)\n",
    "* find probabilistic model; w = spherical Gaussian\n",
    "* alpha, delta = [gamma distrubtions](https://en.wikipedia.org/wiki/Gamma_distribution)\n",
    "\n",
    "[api](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.BayesianRidge.html#sklearn.linear_model.BayesianRidge) | [example](plot_bayesian_ridge.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50000013]\n",
      "[ 0.49999993  0.49999993]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "X = [[0., 0.], [1., 1.], [2., 2.], [3., 3.]]\n",
    "Y = [0., 1., 2., 3.]\n",
    "reg = linear_model.BayesianRidge()\n",
    "reg.fit(X, Y)\n",
    "\n",
    "print(reg.predict ([[1, 0.]]))\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTO RELEVANCE DETERMINATION (ARD)\n",
    "\n",
    "* similar to BayesRidge, can lead to sparser weights\n",
    "* drops assumption of Gaussian being spherical\n",
    "* assumes instead: axis-parallel, elliptical, Gaussian\n",
    "* each coord in w has unique deviation\n",
    "\n",
    "[example](plot_ard.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION\n",
    "\n",
    "* also: logit regression, max-entropy classifier, log-linear classifier\n",
    "* [logistic function](https://en.wikipedia.org/wiki/Logistic_function)\n",
    "* can fit binary, 1vsRest or multinomial LR with optional l1,l2\n",
    "* small dataset or l1 penalty:'liblinear'\n",
    "* large dataset or multinomial loss: 'newton-cg'\n",
    "* vlrge dataset: 'sag'\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) |\n",
    "[L1 vs sparsity, digit images](plot_logistic_l1_l2_sparsity.ipynb) | [logistic path, IRIS images](plot_logistic_path.ipynb) | [decision surface, multi-nomial vs one-vs-rest, make_blobs()](plot_logistic_multinomial.ipynb)\n",
    "\n",
    "[CTR prediction w/ LR](https://turi.com/learn/gallery/notebooks/click_through_rate_prediction_intro.html)\n",
    "\n",
    "### LOGISTIC REGRESSION w/ CV\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOCHASTIC GRADIENT DESCENT\n",
    "\n",
    "* Use case: #samples and/or #features = very large (10^5 fine)\n",
    "* multiple convex loss funcs & penalties\n",
    "* SGDclassifier + loss=\"log\" ==> logistic regression\n",
    "* SGDclassifier + loss=\"hinge\" ==> linear SVM\n",
    "\n",
    "[notebook](stochastic-gradient-descent-SGD.ipynb) | [SGD classifer (API)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) | [SGD regressor (API)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:  [1]\n",
      "coef:     [[ 9.91080278  9.91080278]]\n",
      "intercpt: [-9.99002993]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"predict: \",clf.predict([[2., 2.]]))\n",
    "print(\"coef:    \",clf.coef_)\n",
    "print(\"intercpt:\",clf.intercept_)\n",
    "#print(\"decision function: \",clf.decision_function([[2.,2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SGD: max margin separating hyperplane](plot_sgd_separating_hyperplane.ipynb) |\n",
    "[SGD: multiclass, iris dataset](plot_sgd_iris.ipynb) |\n",
    "[SGD: weighted samples](plot_sgd_weighted_samples.ipynb) |\n",
    "[SGD: various online solvers](plot_sgd_comparison.ipynb) |\n",
    "[SVM: unbalanced classes](plot_separating_hyperplane_unbalanced.ipynb)\n",
    "\n",
    "[SGD: sparse data: text doc classification](document_classification_20newsgroups.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERCEPTRON\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PASSIVE-AGGRESSIVE ALGOS\n",
    "\n",
    "[Classifier (API)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html#sklearn.linear_model.PassiveAggressiveClassifier) | \n",
    "[Regressor (API)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html#sklearn.linear_model.PassiveAggressiveRegressor)\n",
    "\n",
    "[Classifier example](plot_out_of_core_classification.ipynb) | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANSAC (ROBUSTNESS TO OUTLIERS)\n",
    "\n",
    "[example](plot_ransac.ipynb) | [linear estimator fit, sine function](plot_robust_fit.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THEIL-SAN ESTIMATOR\n",
    "\n",
    "[example](plot_theilsen.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUBER REGRESSOR\n",
    "\n",
    "[HR vs Ridge, toy dataset](plot_huber_vs_ridge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   1.,   0.,   0.,   1.],\n",
       "       [  1.,   2.,   3.,   4.,   6.,   9.],\n",
       "       [  1.,   4.,   5.,  16.,  20.,  25.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., -2.,  1., -1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing streamlined with pipeline tools\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "                  ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "# fit to an order-3 polynomial data\n",
    "x = np.arange(5)\n",
    "y = 3 - 2 * x + x ** 2 - x ** 3\n",
    "model = model.fit(x[:, np.newaxis], y)\n",
    "model.named_steps['linear'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking \"interaction features\"\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = X[:, 0] ^ X[:, 1]\n",
    "y\n",
    "\n",
    "X = PolynomialFeatures(interaction_only=True).fit_transform(X).astype(int)\n",
    "X\n",
    "\n",
    "clf = Perceptron(fit_intercept=False, n_iter=10, shuffle=False).fit(X, y)\n",
    "clf.predict(X)\n",
    "\n",
    "clf.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
