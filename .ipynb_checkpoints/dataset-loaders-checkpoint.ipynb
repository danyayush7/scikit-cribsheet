{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General dataset API\n",
    "\n",
    "* 3 interfaces\n",
    "* 1) sample images = tuple (X,y); X = array(#samples,#features); y = array_of_targets(size=#samples)\n",
    "* 2) toy, \"real world\" & mldata.org datasets = dictionary of 2a) array(#samples,#features) + array_of_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy dataset loaders\n",
    "\n",
    "* Too small to be considered real-world datasets\n",
    "\n",
    "[boston](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston) | [iris](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) | [diabetes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) | [digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) | [linnerud](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html#sklearn.datasets.load_linnerud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample image loaders\n",
    "\n",
    "* sample JPEG images, Creative Commons license\n",
    "\n",
    "[all](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_images.html#sklearn.datasets.load_sample_images) | [by_name](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_sample_image.html#sklearn.datasets.load_sample_image) | [demo](plot_color_quantization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sample set generators\n",
    "\n",
    "** Classification** \n",
    "\n",
    "[make_blobs](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs) - controls centers & std devs of clusters\n",
    "\n",
    "[make_classification](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification) - introduces noise\n",
    "\n",
    "[make_gaussian_quantiles](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_gaussian_quantiles.html#sklearn.datasets.make_gaussian_quantiles) - divides single Gaussian into classes separated by concentric hyperspheres\n",
    "\n",
    "[make_hastie_10_2](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_hastie_10_2.html#sklearn.datasets.make_hastie_10_2) - generates data for binary classification\n",
    "\n",
    "[make_cirlces](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html#sklearn.datasets.make_circles), [make_moons](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html#sklearn.datasets.make_moons)  - generates 2D binary classification datasets\n",
    "\n",
    "** Classification (Multilabel) **\n",
    "\n",
    "[make_multilabel_classification](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html#sklearn.datasets.make_multilabel_classification) | [demo](plot_random_multilabel_dataset.ipynb)\n",
    "\n",
    "** BiClustering **\n",
    "\n",
    "[make_biclusters](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_biclusters.html#sklearn.datasets.make_biclusters) - generate array with constant block diagonal struct for biclustering\n",
    "\n",
    "[make_checkerboard](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_checkerboard.html#sklearn.datasets.make_checkerboard) - generate array for block checkboard struct for biclustering\n",
    "\n",
    "** For Regression: **\n",
    "\n",
    "[make_regression](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression)\n",
    "\n",
    "[make_sparse_uncorrelated](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_uncorrelated.html#sklearn.datasets.make_sparse_uncorrelated)\n",
    "\n",
    "[make_friedman1](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html#sklearn.datasets.make_friedman1) - polynomial & since tranforms\n",
    "\n",
    "[make_friedman2](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman2.html#sklearn.datasets.make_friedman2) - feature multiplication & reciprocation\n",
    "\n",
    "[make_friedman3](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman3.html#sklearn.datasets.make_friedman3) - arctan transformation\n",
    "\n",
    "** Manifolds **\n",
    "\n",
    "[make_s_curve](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html#sklearn.datasets.make_s_curve)\n",
    "\n",
    "[make_swiss_roll](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html#sklearn.datasets.make_swiss_roll)\n",
    "\n",
    "** Decomposition **\n",
    "\n",
    "[make_low_rank_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_low_rank_matrix.html#sklearn.datasets.make_low_rank_matrix)\n",
    "\n",
    "[make_sparse_coded_signal](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_coded_signal.html#sklearn.datasets.make_sparse_coded_signal)\n",
    "\n",
    "[make_spd_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html#sklearn.datasets.make_spd_matrix)\n",
    "\n",
    "[make_spase_spd_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_sparse_spd_matrix.html#sklearn.datasets.make_sparse_spd_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMlight / Libsvm format\n",
    "\n",
    "* <label> <feature#>:<value>,... suitable for sparse datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "#X_train, y_train = load_svmlight_file(\n",
    "#    \"/path/to/train_dataset.txt\")\n",
    "\n",
    "# load 2+ datasets at once\n",
    "#X_train, y_train, X_test, y_test = load_svmlight_files(\n",
    "#    (\"/path/to/train_dataset.txt\",\n",
    "#     \"/path/to/test_dataset.txt\"))\n",
    "\n",
    "# fix #features\n",
    "#X_test, y_test = load_svmlight_file(\n",
    "#    \"/path/to/test_dataset.txt\", \n",
    "#    n_features=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External dataset loaders\n",
    "\n",
    "* CSV, Excel, JSON, SQL -- [pandas.io](http://pandas.pydata.org/pandas-docs/stable/io.html)\n",
    "\n",
    "* Binary formats, .mat, .arff, etc -- [scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html)\n",
    "\n",
    "* Columnar data => numpy arrays -- [numpy/routines.io](http://docs.scipy.org/doc/numpy/reference/routines.io.html)\n",
    "\n",
    "* Directories of text files (dirname = category name, file = sample of category) -- [load_files](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html)\n",
    "\n",
    "* Images -- [skimage.io](http://scikit-image.org/docs/dev/api/skimage.io.html), [imageio](http://imageio.readthedocs.io/en/latest/userapi.html)\n",
    "\n",
    "* Images w/ pixel intensities -- [imread](http://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imread.html#scipy.misc.imread) -- requires [pillow](https://pypi.python.org/pypi/Pillow)\n",
    "\n",
    "* Audio (WAV) files -- [scipy](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html)\n",
    "\n",
    "* Category data stored as strings (common in Pandas) -- convert to one-hot variables using [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)\n",
    "\n",
    "* Best practice: optimized file format such as HDF5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "[Olivetti faces](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces) -- 10 images (64x64) x 40 subjects; quantized to 256 grey levels, stored as 8b integers; loader converts to floating point along [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "faces = datasets.fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newsgroups\n",
    "\n",
    "* 18000 posts x 20 topics => 1 training subset, 1 testing subset (split is date-based)\n",
    "\n",
    "[fetch_20newsgroups](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups) -- returns list of raw texts\n",
    "\n",
    "[fetch_20newsgroups_vectorized](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized) -- returns \"ready-to-use\" (feature extractor not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n",
      "(11314,)\n",
      "(11314,)\n",
      "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names))\n",
    "\n",
    "pprint(newsgroups_train.filenames.shape)\n",
    "pprint(newsgroups_train.target.shape)\n",
    "pprint(newsgroups_train.target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073,)\n",
      "(1073,)\n",
      "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#load subset of categories\n",
    "\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "list(newsgroups_train.target_names)\n",
    "\n",
    "pprint(newsgroups_train.filenames.shape)\n",
    "pprint(newsgroups_train.target.shape)\n",
    "pprint(newsgroups_train.target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 34118)\n"
     ]
    }
   ],
   "source": [
    "# to text into TF-IDF vectors, from a subset\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "pprint(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159.0132743362832"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracted vectors should be very sparse\n",
    "vectors.nnz / float(vectors.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88213592402729568\n"
     ]
    }
   ],
   "source": [
    "# filtering text for more realistic training\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     categories=categories)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "pred = clf.predict(vectors_test)\n",
    "\n",
    "pprint(metrics.f1_score(\n",
    "        newsgroups_test.target, \n",
    "        pred, \n",
    "        average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: edu it and in you that is of to the\n",
      "comp.graphics: edu in graphics it is for and of to the\n",
      "sci.space: edu it that is in and space to of the\n",
      "talk.religion.misc: not it you in is that and to of the\n"
     ]
    }
   ],
   "source": [
    "# show most informative features\n",
    "\n",
    "import numpy as np\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(clf, vectorizer, newsgroups_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77310350681274775\n"
     ]
    }
   ],
   "source": [
    "# remove headers, signature blocks, quote blocks\n",
    "# see how f-score goes down\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "pred = clf.predict(vectors_test)\n",
    "\n",
    "pprint(metrics.f1_score(pred, \n",
    "                        newsgroups_test.target, \n",
    "                        average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76995175184521725\n"
     ]
    }
   ],
   "source": [
    "# remove metadata -- f-score declines further\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "pred = clf.predict(vectors_test)\n",
    "\n",
    "pprint(metrics.f1_score(newsgroups_test.target, \n",
    "                        pred, \n",
    "                        average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLdata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])\n"
     ]
    }
   ],
   "source": [
    "#fetch MNIST digit recognition dataset\n",
    "# 70K samples, 28x28 pixels each, labeled with 0-9\n",
    "# default data_home = ~/scikit_learn_data/\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=\"mnist.data\")\n",
    "\n",
    "pprint(mnist.data.shape)\n",
    "pprint(mnist.target.shape)\n",
    "pprint(np.unique(mnist.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(4, 150)\n"
     ]
    }
   ],
   "source": [
    "#mldata usually shaped as (#features,#samples)\n",
    "# opposite of scikit convention\n",
    "# scikit transposes matrix by default\n",
    "\n",
    "iris = fetch_mldata('iris', data_home=\"custom_data_home_test\")\n",
    "pprint(iris.data.shape)\n",
    "\n",
    "iris = fetch_mldata('iris', transpose_data=False,\n",
    "                    data_home=\"custom_data_home_test\")\n",
    "pprint(iris.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faces in the wild\n",
    "\n",
    "[fetch_people](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people)\n",
    "\n",
    "[fetch_pairs](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_pairs.html#sklearn.datasets.fetch_lfw_pairs) - data divided into training, devt, test and \"10_folds\" eval sets\n",
    "\n",
    "* auto-download, cache, parse metadata, decode jpeg, convert slices\n",
    "* into memmapped numpy arrays \n",
    "* dataset size >200MB\n",
    "* [paper](http://vis-www.cs.umass.edu/lfw/lfw.pdf) | [demo](face_recognition.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ariel Sharon'\n",
      "'Colin Powell'\n",
      "'Donald Rumsfeld'\n",
      "'George W Bush'\n",
      "'Gerhard Schroeder'\n",
      "'Hugo Chavez'\n",
      "'Tony Blair'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "for name in lfw_people.target_names:\n",
    "    pprint(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype('float32')\n",
      "(1288, 1850)\n",
      "(1288, 50, 37)\n",
      "(1288,)\n",
      "array([5, 6, 3, 1, 0, 1, 3, 4, 3, 0])\n"
     ]
    }
   ],
   "source": [
    "# default slice\n",
    "pprint(lfw_people.data.dtype)\n",
    "pprint(lfw_people.data.shape)\n",
    "pprint(lfw_people.images.shape)\n",
    "pprint(lfw_people.target.shape)\n",
    "pprint(lfw_people.target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 2, 62, 47)\n",
      "(2200, 5828)\n",
      "(2200,)\n"
     ]
    }
   ],
   "source": [
    "# for face verification: \n",
    "# each sample = pair of pictures belonging (or not) to the same person\n",
    "from sklearn.datasets import fetch_lfw_pairs\n",
    "lfw_pairs_train = fetch_lfw_pairs(subset='train')\n",
    "\n",
    "list(lfw_pairs_train.target_names)\n",
    "pprint(lfw_pairs_train.pairs.shape)\n",
    "pprint(lfw_pairs_train.data.shape)\n",
    "pprint(lfw_pairs_train.target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Forest covertypes](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype)\n",
    "\n",
    "* 30m x 30m forest patches, 7 covertypes (tree species), 54 features/sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'Forest covertype dataset.\\n'\n",
      "          '\\n'\n",
      "          'A classic dataset for classification benchmarks, featuring '\n",
      "          'categorical and\\n'\n",
      "          'real-valued features.\\n'\n",
      "          '\\n'\n",
      "          'The dataset page is available from UCI Machine Learning Repository\\n'\n",
      "          '\\n'\n",
      "          '    http://archive.ics.uci.edu/ml/datasets/Covertype\\n'\n",
      "          '\\n'\n",
      "          'Courtesy of Jock A. Blackard and Colorado State University.\\n',\n",
      " 'data': array([[  2.59600000e+03,   5.10000000e+01,   3.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  2.59000000e+03,   5.60000000e+01,   2.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  2.80400000e+03,   1.39000000e+02,   9.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       ..., \n",
      "       [  2.38600000e+03,   1.59000000e+02,   1.70000000e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  2.38400000e+03,   1.70000000e+02,   1.50000000e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  2.38300000e+03,   1.65000000e+02,   1.30000000e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]),\n",
      " 'target': array([5, 5, 2, ..., 3, 3, 3], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "covtypes = fetch_covtype()\n",
    "pprint(covtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [RCV1](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_rcv1.html#sklearn.datasets.fetch_rcv1) -- Reuters corpus vol#1\n",
    "\n",
    "* 800K Reuters stories; compressed size ~656MB\n",
    "* scipy CSR sparse matrix, >800K samples, 47K features\n",
    "* 1st 23K = training set, remain 780K = test set\n",
    "* 0.16% of values are non-zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "rcv1 = fetch_rcv1()\n",
    "\n",
    "pprint(rcv1.data.shape)\n",
    "pprint(rcv1.target.shape)\n",
    "pprint(rcv1.sample_id[:3])\n",
    "pprint(rcv1.target_names[:3].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Boston house prices](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston)\n",
    "\n",
    "* 506 samples, 13 attributes\n",
    "* no missing attributes\n",
    "* used for regression examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Wisconsin breast cancer DB](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "\n",
    "* 569 samples, 30 attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Diabetes predictor](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes)\n",
    "\n",
    "* 442 instances, 10 predictor vals (numeric) + 1 progresson measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits)\n",
    "\n",
    "* 5620 samples, 64 attributes, 8x8 image of integer [0-16] pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Iris Plants DB](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)\n",
    "\n",
    "* 150 samples, 4 attributes, no missing attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Linnerrud](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_linnerud.html#sklearn.datasets.load_linnerud)\n",
    "\n",
    "* 20 samples, 3 attributes, no missing attributes\n",
    "* exercise data (weight,waist,pulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
