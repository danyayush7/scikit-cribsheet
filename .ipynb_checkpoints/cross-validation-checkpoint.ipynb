{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRO\n",
    "\n",
    "* common practice: reserve part of data set as a **test set**.\n",
    "* training/test splits easily done by [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)\n",
    "* basic approach = \"k-fold\" CV: training set split into k smaller sets\n",
    "   * training done on k-1 subsets\n",
    "   * validation done on remaining subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 4), (90,), (60, 4), (60,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hold 40% of data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) |\n",
    "[demo1](plot_cv_diabetes.ipynb) |\n",
    "[demo2](plot_cv_digits.ipynb) |\n",
    "[underfit vs overfit](plot_underfitting_overfitting.ipynb) |\n",
    "[nested vs unnested](plot_nested_cross_validation_iris.ipynb)\n",
    "\n",
    "* simplest example of CV: [cross_val_score]\n",
    "* estimates accuracy of linear SVM on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (0.98000000000000009, 0.032659863237109031)\n"
     ]
    }
   ],
   "source": [
    "# CV base example - return mean score & 95% confidence interval\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "\n",
    "print(\"Accuracy:\",(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (0.9799498746867169, 0.032741717530936382)\n"
     ]
    }
   ],
   "source": [
    "# CV with a different scoring method\n",
    "from sklearn import metrics\n",
    "scores = cross_val_score(\n",
    "    clf, iris.data, iris.target, \n",
    "    cv=5, \n",
    "    scoring='f1_macro')\n",
    "print(\"Accuracy:\",(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: (0.98518518518518527, 0.020951312035156995)\n"
     ]
    }
   ],
   "source": [
    "# CV with custom iterator\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = iris.data.shape[0]\n",
    "\n",
    "cv = ShuffleSplit(\n",
    "    n_splits=3, \n",
    "    test_size=0.3, \n",
    "    random_state=0)\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf, iris.data, iris.target, cv=cv)\n",
    "print(\"Accuracy:\",(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions via CV\n",
    "\n",
    "* returns prediction value for each element in input\n",
    "\n",
    "[cross_val_predict](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) | [demo](plot_cv_predict.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97333333333333338"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "predicted = cross_val_predict(\n",
    "    clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "metrics.accuracy_score(iris.target, predicted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[demo: ROC with CV](plot_roc_crossval.ipynb) | \n",
    "[recursive feature elimination (RFE) with CV](plot_rfe_with_cross_validation.ipynb) | \n",
    "[param estimation using grid search with CV](grid_search_digits.ipynb) \n",
    "\n",
    "[sample pipeline, text feature extract/eval](grid_search_text_feature_extraction.ipynb) | \n",
    "[plot CV'd predictions](plot_cv_predict.ipynb) |\n",
    "[nested vs non-nested CV](plot_nested_cross_validation_iris.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Iterators (Utilities to generate indices for dataset splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold\n",
    "\n",
    "* Divide all samples into k groups of ideally equal sizes\n",
    "* training done with k-1 groups; test with remaining set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "# K=2 fold CV, 4-sample dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out\n",
    "\n",
    "* Each set = taking all samples but one (the test set)\n",
    "* for n samples: n different training sets, n different test sets\n",
    "* computationally more expensive than K-fold\n",
    "* rule of thumb: 5x-10x cv preferred to LOO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7] [0]\n",
      "[0 2 3 4 5 6 7] [1]\n",
      "[0 1 3 4 5 6 7] [2]\n",
      "[0 1 2 4 5 6 7] [3]\n",
      "[0 1 2 3 5 6 7] [4]\n",
      "[0 1 2 3 4 6 7] [5]\n",
      "[0 1 2 3 4 5 7] [6]\n",
      "[0 1 2 3 4 5 6] [7]\n"
     ]
    }
   ],
   "source": [
    "# leave-one-out (LOO)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "X = [1,2,3,4,5,6,7,8]\n",
    "loo = LeaveOneOut()\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave P out\n",
    "\n",
    "* removes p samples from complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5] [0 1]\n",
      "[1 3 4 5] [0 2]\n",
      "[1 2 4 5] [0 3]\n",
      "[1 2 3 5] [0 4]\n",
      "[1 2 3 4] [0 5]\n",
      "[0 3 4 5] [1 2]\n",
      "[0 2 4 5] [1 3]\n",
      "[0 2 3 5] [1 4]\n",
      "[0 2 3 4] [1 5]\n",
      "[0 1 4 5] [2 3]\n",
      "[0 1 3 5] [2 4]\n",
      "[0 1 3 4] [2 5]\n",
      "[0 1 2 5] [3 4]\n",
      "[0 1 2 4] [3 5]\n",
      "[0 1 2 3] [4 5]\n"
     ]
    }
   ],
   "source": [
    "# leave P out (LPO)\n",
    "from sklearn.model_selection import LeavePOut\n",
    "\n",
    "X = np.ones(6)\n",
    "lpo = LeavePOut(p=2)\n",
    "for train, test in lpo.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle & Split (Random Permutations)\n",
    "\n",
    "* generates user-defined #independent train/test splits\n",
    "* good alternative to K-fold (finer #iterations controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 7 3 0 5 4] [6 2]\n",
      "[3 7 0 4 2 5] [1 6]\n",
      "[3 4 7 0 6 1] [5 2]\n",
      "[6 7 3 4 1 0] [2 5]\n"
     ]
    }
   ],
   "source": [
    "# shuffle and split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "X = np.arange(8)\n",
    "ss = ShuffleSplit(\n",
    "    n_splits=4, \n",
    "    test_size=0.25, \n",
    "    random_state=0)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print(\"%s %s\" % (train_index, test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV iterators with label-based stratification\n",
    "\n",
    "* use case: classification with large class distribution inbalance\n",
    "\n",
    "[stratified k-fold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) - each test set approx the same #samples from each class as the complete set.\n",
    "\n",
    "[stratified shuffle split]() - preserves same pct for each target class as in the complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  6  7  8 10 11] [0 1 4 5 9]\n",
      "[ 0  1  3  4  5  8  9 11] [ 2  6  7 10]\n",
      "[ 0  1  2  4  5  6  7  9 10] [ 3  8 11]\n"
     ]
    }
   ],
   "source": [
    "# stratified K-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.ones(12)\n",
    "y = [0,0,0,0,1,1,1,1,1,2,2,2]\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [3 0]\n",
      "[0 2] [1 3]\n",
      "[0 2] [3 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "sss = StratifiedShuffleSplit(\n",
    "    n_splits=3, \n",
    "    test_size=0.5, \n",
    "    random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "      \n",
    "for train_index, test_index in sss.split(X, y):\n",
    "   print(train_index, test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV iterators for grouped (dependent) data\n",
    "\n",
    "* Domain-specific problem\n",
    "* Use case: determine if a model trained on a specific group generalizes well to the unseen groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped K-fold\n",
    "\n",
    "* Ensures a given group not present in both training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5] [6 7 8 9]\n",
      "[0 1 2 6 7 8 9] [3 4 5]\n",
      "[3 4 5 6 7 8 9] [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# example: 3 subjects (1-3); each subject in different test fold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X =      [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "y =      [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
    "groups = [1,    1,   1,   2,   2,   2,   3,   3,   3,   3]\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "for train, test in gkf.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Leave One Group Out](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6] [0 1]\n",
      "[0 1 4 5 6] [2 3]\n",
      "[0 1 2 3] [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# leave one group out\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X =      [1, 5, 10, 50, 60, 70, 80]\n",
    "y =      [0, 1,  1,  2,  2,  2,  2]\n",
    "groups = [1, 1,  2,  2,  3,  3,  3]\n",
    "logo = LeaveOneGroupOut()\n",
    "for train, test in logo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Leave P Groups out](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut)\n",
    "\n",
    "* Generates sequence of random partitions - subset of groups are held out for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5] [0 1 2 3]\n",
      "[2 3] [0 1 4 5]\n",
      "[0 1] [2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# leave P groups out\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "X =      np.arange(6)\n",
    "y =      [1, 1, 1, 2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3]\n",
    "lpgo = LeavePGroupsOut(n_groups=2)\n",
    "for train, test in lpgo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Group Shuffle Split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit)\n",
    "\n",
    "* use case: when behavior of LeavePGroupsOut is needed, but #groups is prohibitively large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [4 5 6 7]\n",
      "[2 3 6 7] [0 1 4 5]\n",
      "[2 3 4 5] [0 1 6 7]\n",
      "[4 5 6 7] [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# group shuffle split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "X =      [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]\n",
    "y =      [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"]\n",
    "groups = [1,    1,   2,   2,   3,   3,   4,   4]\n",
    "\n",
    "gss = GroupShuffleSplit(\n",
    "    n_splits=4, \n",
    "    test_size=0.5, \n",
    "    random_state=0)\n",
    "\n",
    "for train, test in gss.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Predefined splts](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredefinedSplit(test_fold=array([ 0,  1, -1,  1]))\n",
      "TRAIN: [1 2 3] TEST: [0]\n",
      "TRAIN: [0 2] TEST: [1 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "X =         np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y =         np.array([ 0,      0,      1,      1])\n",
    "test_fold =          [ 0,      1,     -1,      1]\n",
    "\n",
    "ps = PredefinedSplit(test_fold)\n",
    "ps.get_n_splits()\n",
    "\n",
    "print(ps)       \n",
    "\n",
    "for train_index, test_index in ps.split():\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Time Series Split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit)\n",
    "\n",
    "* returns first k folds as training set, next k+1 fold as test set.\n",
    "* successive training sets are supersets of previous ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(n_splits=3)\n",
      "[0 1 2] [3]\n",
      "[0 1 2 3] [4]\n",
      "[0 1 2 3 4] [5]\n"
     ]
    }
   ],
   "source": [
    "# example, 3-series split, 6 items\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)  \n",
    "\n",
    "for train, test in tscv.split(X):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling\n",
    "\n",
    "* use case: when data order is not arbitrary\n",
    "* some iterators (ex: K-fold) have built-in shuffling option"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
