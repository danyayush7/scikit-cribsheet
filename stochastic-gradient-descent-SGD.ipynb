{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### INTRO\n",
    "\n",
    "* Wide use, very scalable\n",
    "* large #parameters, #iterations reqd\n",
    "* sensitive to feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD CLASSIFICATION\n",
    "\n",
    "* loss functions: 'hinge' (SVM),'modified_huber','log' (LR)\n",
    "* 'log'/'modified_huber': .predict_proba (returns prob ests per sample)\n",
    "* penalty options:\n",
    "   * penalty='l2'; l2 norm (default)\n",
    "   * penalty='l1'; l1 norm\n",
    "   * penalty='elasticnet'; convex combo of l1,l2\n",
    "\n",
    "* supports multiclass by combining binary classifiers, 1vsAll scheme\n",
    "\n",
    "* coef_ = 2D (#classes,#features)\n",
    "* intercept_ = 1D (#classes)\n",
    "* classes_ = index of classes, ascending order\n",
    "\n",
    "* weighted classes/instances supported (class_weight, sample_weight)\n",
    "\n",
    "[SGD: max margin separating hyperplane](plot_sgd_separating_hyperplane.ipynb) |\n",
    "[SGD: multiclass, iris dataset](plot_sgd_iris.ipynb) |\n",
    "[SGD: weighted samples](plot_sgd_weighted_samples.ipynb) |\n",
    "[SGD: various online solvers](plot_sgd_comparison.ipynb) |\n",
    "[SVM: unbalanced classes](plot_separating_hyperplane_unbalanced.ipynb)\n",
    "\n",
    "[SGD: sparse data: text doc classification](document_classification_20newsgroups.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[[ 9.91080278  9.91080278]]\n",
      "[-9.99002993]\n",
      "[ 29.65318117]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "X = [[0.0, 0.0], [1.0, 1.0]]\n",
    "y = [0, 1]\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([\n",
    "            [2.0,2.0]]))\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.decision_function([[2.0,2.0]])) # distance to hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00459185,  0.99540815]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"log\").fit(X, y)\n",
    "clf.predict_proba([[1., 1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD REGRESSION\n",
    "\n",
    "* Use case: Vlarge #training samples (>10K).\n",
    "* loss function controlled by .loss ('squared_loss','huber','epsilon_insensitive')\n",
    "\n",
    "[API](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor) |\n",
    "[demo: prediction latency](plot_prediction_latency.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "n_samples, n_features = 10, 5\n",
    "np.random.seed(0)\n",
    "y = np.random.randn(n_samples)\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "clf = linear_model.SGDRegressor()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARSE DATA\n",
    "\n",
    "* any scipy.sparse format OK; use scipy.sparse.csr_matrix for best results\n",
    "\n",
    "[demo:textdoc class](document_classification_20newsgroups.ipynb) *** BUGGED ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIPS\n",
    "\n",
    "* sensitive to feature scaling -- scale your data [0,1],[-1,+1],mean0.0/var1.0\n",
    "* find reasonable alpha using [GridSearchCV](), range 10.0**-np.arange(1,7) = .1,.001,.001,.0001,.00001,.000001\n",
    "* typical convergence after ~10^6 samples; default n_iter = np.ceil(10**6/#samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
